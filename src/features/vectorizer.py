# features/vectorizer.py

import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib

# === è·¯å¾‘è¨­å®š ===
INPUT_FILE = "data/processed/clean_articles.csv"
MODEL_DIR = "outputs/models"
VECTORIZER_PATH = os.path.join(MODEL_DIR, "tfidf_vectorizer.pkl")
MATRIX_PATH = os.path.join(MODEL_DIR, "tfidf_matrix.pkl")

# === å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾ ===
os.makedirs(MODEL_DIR, exist_ok=True)

# === è®€å–è³‡æ–™ ===
print(f"ğŸ“‚ è®€å–è³‡æ–™ï¼š{INPUT_FILE}")
df = pd.read_csv(INPUT_FILE)

# === TF-IDF å‘é‡åŒ– ===
print("ğŸ”„ æ­£åœ¨åŸ·è¡Œ TF-IDF å‘é‡åŒ–...")
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["tokens"].astype(str))  # ç¢ºä¿æ¬„ä½ç‚ºæ–‡å­—

# === å„²å­˜æ¨¡å‹èˆ‡å‘é‡ ===
joblib.dump(vectorizer, VECTORIZER_PATH)
joblib.dump(X, MATRIX_PATH)

print(f"âœ… TF-IDF å‘é‡å„²å­˜è‡³ï¼š{MATRIX_PATH}")
print(f"âœ… å‘é‡å™¨æ¨¡å‹å„²å­˜è‡³ï¼š{VECTORIZER_PATH}")
print(f"ğŸ”¢ å‘é‡ç¶­åº¦ï¼š{X.shape}")
